function isShowHeader() {
return 1;
}

function getFileName() {
return "/Users/Yusuke/git/memo/cresco/giken/article/02_TensorFlow.md";
}

function getFileType() {
return "markdown";
}

function getLastModified() {
return "2017/06/22 (木) 17:08:45";
}

function getContent() {
return "# 02_TensorFlowで画像データからTFRecordsファイルを使って学習させてみた\n## 経緯\n- TensorFlowでも、Caffeと同様にデータセットを単一ファイルにまとめて扱いたかった\n- TensorFlowに於いては、データセットをTFRecords形式で扱うのがパフォーマンス的にも良いとのこと  \n  TFRecords形式でデータセットを作って、学習させてみようと思い立った\n\n## 環境\n- OS: macOS Sierra 10.12.5\n- メモリ: 8GB\n- Python ver: Python 3.6.0 :: Anaconda 4.3.1 (x86_64)\n- TensorFlow\n    - ver: 1.2rc0\n        - 2017/06/14に試したが、6/22に改めて公式を確認したら、正式版として1.2が提供され始めていた\n        - 今回実装したソースコードを1.2で改めて動作確認したが、別段問題は出なかった\n    - CPUモード\n\n\n---\n## TFRecords形式のデータセットの作成・読み込み\n### TFRecords形式とは？\n- [ここ](https://www.tensorflow.org/programmers_guide/reading_data)の **Standard TensorFlow format** に記載がある通り、  \n  TFRecordsはTensorFlow向けの推奨ファイルフォーマット  \n  TFRecordsファイルにはtf.train.Example Protocol Bufferが内包されている\n- tf.train.Example にはバイト文字列や数値などを詰め込むことができるので、画像データもシリアライズすれば詰め込める\n\n\n### TFRecords形式のメリット\n- TensorFlow自身がTFRecords形式のファイルを読み書きする機能を提供している\n- 訓練する際に於いて、画像データを直接読み込むよりも、TFRecords形式に固めたものを利用した方が高速にデータを処理できるとのこと\n    - [参考: Performance Guide](https://www.tensorflow.org/performance/performance_guide)\n\n\n### TFRecordsの作成方法\n- TFRecordWriterオブジェクトを利用して、TFRecords形式のファイルを作成できる。\n\n- 処理の概要\n    1. 教師データ(画像ファイル名とラベルのリスト)と、画像ファイルが格納されているディレクトリを用意\n        - ここでは事前にlistとして変数に格納しておく\n    2. TFRecordWriterオブジェクトを生成\n    3. 教師データを全件走査して下記の処理を実行\n        1. 該当する画像ファイルを読み込み\n        2. 画像データをリサイズ & バイナリ文字列に変換\n        3. TFRecordWriterオブジェクトを使って書き込み\n\n- ソースコード\n\n    ```\n    import tensorflow as tf\n    import numpy as np\n    from PIL import Image\n\n    # 作成するデータセットのファイルパスを指定\n    dataset_path = \"dataset.tfrecords\"\n\n    # 格納する画像サイズの指定: MNISTデータセットの画像を利用したので、H28xW28を指定\n    width, height = [28, 28]\n\n    # クラス数: ラベルをone-hot表現に変換する為に利用\n    class_count = 10\n\n    # 教師データ: 対象画像ファイル名とラベルのリスト\n    # [[画像ファイル名, ラベル], ...]\n    datas = [[\"img0.png\", 0], [\"img2.png\", 2], [\"img1.png\", 1]]\n\n    # TFRecordsファイルに書き出す為、TFRecordWriterオブジェクトを生成\n    writer = tf.python_io.TFRecordWriter(dataset_path)\n\n    for img_name, label in datas:\n        # 画像をリサイズ & バイト文字列に変換\n        img_obj = Image.open(img_name).convert(\"RGB\").resize((width, height))\n        img = np.array(img_obj).tostring() \n\n        # 画像ファイル1件につき、1つのtf.train.Exampleを作成\n        record = tf.train.Example(features=tf.train.Features(feature={\n            \"label\": tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[label])),\n            \"class_count\": tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[class_count])),\n            \"image\": tf.train.Feature(\n                bytes_list=tf.train.BytesList(value=[img])),\n            \"height\": tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[height])),\n            \"width\": tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[width])),\n            \"depth\": tf.train.Feature(\n                int64_list=tf.train.Int64List(value=[3])),\n        }))\n\n        # tf.train.ExampleをTFRecordsファイルに書き込む\n        writer.write(record.SerializeToString())\n\n    writer.close()\n    ```\n\n\n### TFRecordsの読み込み方法\n- TensorFlowでは、queueを利用してファイルの読み込みを行う。\n- TFRecordReaderオブジェクトを利用し、TFRecords形式のファイルを読み込む。\n\n- 処理の概要\n    1. TFRecordsファイルのパスをqueueに詰める\n    2. queue内のTFRecordsファイルを読み込み、デシリアライズする\n    3. デシリアライズしたデータを元の型に変換したり、元のshapeに戻したりする\n\n- ソースコード\n\n    ```\n    import tensorflow as tf\n\n    # 読み込み対象のファイルをqueueに詰める: TFRecordReaderはqueueを利用してファイルを読み込む\n    file_name_queue = tf.train.string_input_producer([file_path])\n\n    # TFRecordsファイルを読み込む為、TFRecordReaderオブジェクトを生成\n    reader = tf.TFRecordReader()\n\n    # 読み込み: ファイルから読み込み、serialized_exampleに格納する\n    _, serialized_example = reader.read(file_name_queue)\n\n    # デシリアライズ: serialized_exampleはシリアライズされているので、デシリアライズする\n    #                 -> Tensorオブジェクトが返却される\n    features = tf.parse_single_example(\n        serialized_example,\n        features={\n            \"class_count\": tf.FixedLenFeature([], tf.int64),\n            \"label\": tf.FixedLenFeature([], tf.int64),\n            \"image\": tf.FixedLenFeature([], tf.string),\n            \"height\": tf.FixedLenFeature([], tf.int64),\n            \"width\": tf.FixedLenFeature([], tf.int64),\n            \"depth\": tf.FixedLenFeature([], tf.int64),\n        })\n\n    # featuresオブジェクト内の要素はTensorオブジェクトとなっている\n    # でも、Tensorオブジェクトに直接アクセスしても中身が見えない\n    # \n    # -> 中身を見る為には、session張ってeval()する\n    # => eval()する為にはCoordinatorオブジェクトを生成して、start_queue_runner()しておく必要がある\n    with tf.Session() as sess:\n        sess.run(tf.local_variables_initializer())\n        \n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        try:\n            # --- 実数値に変換する必要があるもののみeval() ---\n            height = tf.cast(features[\"height\"], tf.int32).eval()\n            width = tf.cast(features[\"width\"], tf.int32).eval()\n            depth = tf.cast(features[\"depth\"], tf.int32).eval()\n            class_count = tf.cast(features[\"class_count\"], tf.int32).eval()\n\n            # --- 画像データとラベルは学習時に適宜取り出したいのでeval()しない ---\n            label = tf.cast(features[\"label\"], tf.int32)\n            # バイト文字列をdecodeし、元のshapeに戻す\n            img = tf.reshape(tf.decode_raw(features[\"image\"], tf.uint8),\n                             tf.stack([height, width, depth]))\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n\n    # labelをone-hot表現に変換\n    label = tf.one_hot(label, class_count)\n    ```\n\n\n### TFRecordsからのミニバッチ単位での取り出し\n- 「TFRecordsの読み込み方法」の、img, labelからミニバッチ単位でデータを取り出す方法\n\n- 処理の概要\n    1. img, labelの値の調整と型変換\n    2. ミニバッチ単位で取り出す為の変数を作成\n    3. ミニバッチ分のデータの取り出し\n\n- ソースコード\n\n    ```\n    # ピクセル値が0 ~ 255の範囲の値を取ってしまっているので、0 ~ 1の範囲の値になるように調整\n    img = tf.cast(img, tf.float32) * (1. / 255)\n    label = tf.cast(label, dtype=tf.float32)\n\n    # ミニバッチのサイズを指定\n    batch_size = 100\n\n    # バッチ単位で取り出せるようにする\n    # 詳細は https://www.tensorflow.org/api_docs/python/tf/train/batch\n    images, sparse_labels = tf.train.batch(\n        [img, label], batch_size=batch_size, num_threads=2,\n        capacity=1000 + 3 * batch_size)\n\n    # あとはsession張ってsess.run()すればバッチ単位でデータを取り出せる\n    sess = tf.InteractiveSession()\n    sess.run(tf.global_variables_initializer())\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n\n    try:\n        # ミニバッチ分のデータを取り出す\n        imgs, labels = sess.run([img, label])\n    finally:\n        coord.request_stop()\n    coord.join(threads)\n\n    sess.close()\n    ```\n\n---\n## 感想\n- TFRecordsは、仕組みが分かれば非常に簡単に扱える。\n- TensorFlowには自動的にミニバッチ単位でデータを取り出してくれる機能がある。便利。\n- TensorFlowはGCP上で動かせるらしいので、試してみたい。\n- 今回触れた以外にも、TensorBoardやTensorFlow-Foldなども使ってみたいと思っている。";
}
